{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "corporate-spectacular",
   "metadata": {},
   "source": [
    "# Generate CFG Input Representation (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "selected-afghanistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import glob\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from spektral.datasets import delaunay\n",
    "from spektral.layers import *\n",
    "from spektral.utils.convolution import localpooling_filter\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tqdm.contrib.concurrent import process_map, thread_map\n",
    "\n",
    "from utils import yaml_load, get_section\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "prime-stamp",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of graphs with adjacency matrix below shape (150, 150): 887\n"
     ]
    }
   ],
   "source": [
    "# Defining some useful variables\n",
    "metadata_file = './data/ccpe-applications-information.yaml'\n",
    "network_input_graph_shape = (150, 150)\n",
    "network_input_features_shape = (150, 200)\n",
    "\n",
    "metadata_info = yaml_load(metadata_file)\n",
    "\n",
    "# Lets filter CFG files whose number of nodes is less than network_input_graph_shape\n",
    "# For example, only CFG graphs with less than 150 nodes. Note: the graphs are represented as adjacency matrix (a quadratic matrix)\n",
    "filtered_graph_files = {\n",
    "    benchmark_name: {\n",
    "        opt_seq: opt_values \n",
    "        for opt_seq, opt_values in values.items() if opt_values['number_cdfg_nodes'] < network_input_graph_shape[0]\n",
    "    } for benchmark_name, values in metadata_info.items()\n",
    "}\n",
    "\n",
    "# Remove applications that has less than 2 graphs with less than network_input_graph_shape\n",
    "filtered_graph_files = {benchmark_name: values for benchmark_name, values in filtered_graph_files.items() if len(values) > 2}\n",
    "print(f\"Number of graphs with adjacency matrix below shape {network_input_graph_shape}: {sum([len(values) for _, values in filtered_graph_files.items()])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-vegetation",
   "metadata": {},
   "source": [
    "And now, we are going to sample graphs (indicated by 'no_samples') from the filtered_graphs (i.e. below a determined shape). \n",
    "\n",
    "To do this we randomly select 'no_samples' applications and then, for each application, we select 2 different graphs (with different optimization sequences). At end, we will have a list of tuples with the following format: \\[(CFGFILE1, CFGFILE2, SPEEDUP), ...\\].\n",
    "\n",
    "*Note*: The graphs are not loaded yet, only the file names are selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "polyphonic-beginning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 20000 CDFGs\n",
      "First sample of 20000 samples (example of output): ('./data/ccpe-dados/cdfg.programl/programl.5000.05/extracted/Shootout.nestedloop.0.51.progaml.yaml', './data/ccpe-dados/cdfg.programl/programl.5000.05/extracted/Shootout.nestedloop.0.19.progaml.yaml', 0.02822142069263094)\n"
     ]
    }
   ],
   "source": [
    "no_samples = 20000  # Number of samples to generate. Each sample is composed by 2 graphs\n",
    "samples = []\n",
    "\n",
    "# Lets choose 'no_samples' random CFG applications and then choose 2 different graphs from each application.\n",
    "# Note: graphs here are the files (the graphs is not loaded yet).\n",
    "# We will have a list of tuples: [(CFGFILE1, CFGFILE2, SPEEDUP), ...]\n",
    "for s in random.choices(list(filtered_graph_files.keys()), k=no_samples):\n",
    "    opt_seq1, opt_seq2 = random.sample(list(filtered_graph_files[s].keys()), 2)\n",
    "    t = (\n",
    "        filtered_graph_files[s][opt_seq1]['cdfg_file'], \n",
    "        filtered_graph_files[s][opt_seq2]['cdfg_file'],\n",
    "        filtered_graph_files[s][opt_seq1]['exectime']/filtered_graph_files[s][opt_seq2]['exectime']\n",
    "    )\n",
    "    samples.append(t)\n",
    "\n",
    "print(f\"Sampled {len(samples)} CDFGs\")\n",
    "print(f\"First sample of {len(samples)} samples (example of output): {samples[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "civil-balance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings\n",
    "embeddings_file = './data/inst2vec/emb.p'\n",
    "embeddings = np.load(embeddings_file, allow_pickle=True)\n",
    "\n",
    "# Load the graph and features from file\n",
    "def load_graph_from_file(filename: str) -> tuple:\n",
    "    x = yaml_load(filename)\n",
    "    return x['edges'], x['edges_features'], x['nodes_features']\n",
    "\n",
    "def generate_graph_matrix(network_shape, features_shape, edges, edge_features, node_features, representation) -> tuple:\n",
    "    valid_edges = {\n",
    "        0: 'control' in representation,\n",
    "        1: 'data' in representation,\n",
    "        2: 'call' in representation\n",
    "    }\n",
    "    \n",
    "    adj_matrix = np.full((network_shape), False, dtype='bool')\n",
    "    feature_matrix = np.empty((features_shape), dtype='float32')\n",
    "    \n",
    "    for edge_no, edge in edges.items():\n",
    "        edge_type = edge_features[edge_no][0]\n",
    "        if valid_edges[edge_type] == True:\n",
    "            adj_matrix[edge[0]][edge[1]] = True\n",
    "    \n",
    "    for node_no, feature_no in node_features.items():\n",
    "        feature_no = feature_no[0]\n",
    "        feature_matrix[node_no] = embeddings[feature_no]\n",
    "        \n",
    "    return adj_matrix, feature_matrix  \n",
    "    \n",
    "\n",
    "def load_sample_file(sample_tuple: tuple, representation_to_generate: tuple) -> tuple:\n",
    "    edges_1, edge_feat_1, feat_1 = load_graph_from_file(sample_tuple[0])\n",
    "    edges_2, edge_feat_2, feat_2 = load_graph_from_file(sample_tuple[1])\n",
    "    \n",
    "    graph1, features1 = generate_graph_matrix(\n",
    "        network_input_graph_shape, network_input_features_shape, edges_1, \n",
    "        edge_feat_1, feat_1, representation_to_generate)\n",
    "    graph2, features2 = generate_graph_matrix(\n",
    "        network_input_graph_shape, network_input_features_shape, edges_2, \n",
    "        edge_feat_2, feat_2, representation_to_generate)\n",
    "    \n",
    "    graphs = np.empty((2, network_input_graph_shape[0], network_input_graph_shape[1]), dtype='bool')\n",
    "    graphs[0] = graph1\n",
    "    graphs[1] = graph2\n",
    "\n",
    "    features = np.empty((2, network_input_features_shape[0], network_input_features_shape[1]), dtype='float32')\n",
    "    features[0] = features1\n",
    "    features[1] = features2\n",
    "\n",
    "    # Returns:\n",
    "    # * A matrix with 2 graphs with shape: (2, network_input_graph_shape[0], network_input_graph_shape[1])\n",
    "    # * A matrix with 2 features with shape: (2, network_input_features_shape[0], network_input_features_shape[1])\n",
    "    # * A float with speedup of CFG1/CFG2\n",
    "    return graphs, features, np.array([sample_tuple[2]], dtype='float32')\n",
    "\n",
    "\n",
    "def generate_sample(samples, representation, desc='Samples generated'):\n",
    "    for rep in representation:\n",
    "        assert rep in ['control', 'data', 'call'], f\"Invalid representation {rep}\"\n",
    "    \n",
    "    input_graphs = np.empty((len(samples), 2, network_input_graph_shape[0], network_input_graph_shape[1]), dtype='bool')\n",
    "    input_features = np.empty((len(samples), 2, network_input_features_shape[0], network_input_features_shape[1]), dtype='float32')\n",
    "    speedups = np.empty((len(samples), 1), dtype='float32')\n",
    "\n",
    "    i = 0\n",
    "    for sample in tqdm.tqdm(samples, desc=desc):\n",
    "        # This function return a list of tuples, where each tuple is composed by:\n",
    "        # np.array with 2 graphs, np.array with 2 features, speedup\n",
    "        graphs, features, speedup = load_sample_file(sample, representation)\n",
    "        input_graphs[i] = graphs\n",
    "        input_features[i] = features\n",
    "        speedups[i] = speedup\n",
    "        i += 1\n",
    "\n",
    "    print(f\"Number of samples loaded: {len(samples)}\")\n",
    "    print(f\"Input graphs shape: {input_graphs.shape}\")\n",
    "    print(f\"Input features shape: {input_features.shape}\")\n",
    "    print(f\"Input speedups (target) shape: {speedups.shape}\")\n",
    "    \n",
    "    #np.savez_compressed(output_file, graphs=input_graphs, features=input_features, speedups=speedups)\n",
    "    #print(f\"Representation {representation} saved to {output_file}\")\n",
    "    return input_graphs, input_features, speedups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ethical-cigarette",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Samples generated: 100%|██████████| 20000/20000 [06:50<00:00, 48.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples loaded: 20000\n",
      "Input graphs shape: (20000, 2, 150, 150)\n",
      "Input features shape: (20000, 2, 150, 200)\n",
      "Input speedups (target) shape: (20000, 1)\n",
      "Data saved to ./data/cdfg_control-data-call_20000samples_150x150.npz\n",
      "Samples information saved to ./data/selected_cdfg_control-data-call_20000samples_150x150.yaml\n"
     ]
    }
   ],
   "source": [
    "representation = ('control', 'data', 'call')\n",
    "\n",
    "output_data_file = f\"./data/cdfg_{'-'.join(representation)}_{no_samples}samples_{network_input_graph_shape[0]}x{network_input_graph_shape[1]}\"\n",
    "input_graphs, input_features, speedups = generate_sample(samples, representation)\n",
    "np.savez_compressed(output_data_file, graphs=input_graphs, features=input_features, speedups=speedups)\n",
    "print(f\"Data saved to {output_data_file}.npz\")\n",
    "\n",
    "output_samples_file = f\"./data/selected_cdfg_{'-'.join(representation)}_{no_samples}samples_{network_input_graph_shape[0]}x{network_input_graph_shape[1]}.yaml\"\n",
    "with open(output_samples_file, 'wt') as f:\n",
    "    yaml.dump(samples, f)\n",
    "print(f\"Samples information saved to {output_samples_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "parallel-combination",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Samples generated: 100%|██████████| 20000/20000 [06:50<00:00, 48.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples loaded: 20000\n",
      "Input graphs shape: (20000, 2, 150, 150)\n",
      "Input features shape: (20000, 2, 150, 200)\n",
      "Input speedups (target) shape: (20000, 1)\n",
      "Data saved to ./data/cdfg_control-data_20000samples_150x150.npz\n",
      "Samples information saved to ./data/selected_cdfg_control-data_20000samples_150x150.yaml\n"
     ]
    }
   ],
   "source": [
    "representation = ('control', 'data')\n",
    "\n",
    "output_data_file = f\"./data/cdfg_{'-'.join(representation)}_{no_samples}samples_{network_input_graph_shape[0]}x{network_input_graph_shape[1]}\"\n",
    "input_graphs, input_features, speedups = generate_sample(samples, representation)\n",
    "np.savez_compressed(output_data_file, graphs=input_graphs, features=input_features, speedups=speedups)\n",
    "print(f\"Data saved to {output_data_file}.npz\")\n",
    "\n",
    "output_samples_file = f\"./data/selected_cdfg_{'-'.join(representation)}_{no_samples}samples_{network_input_graph_shape[0]}x{network_input_graph_shape[1]}.yaml\"\n",
    "with open(output_samples_file, 'wt') as f:\n",
    "    yaml.dump(samples, f)\n",
    "print(f\"Samples information saved to {output_samples_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "exact-avatar",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Samples generated: 100%|██████████| 20000/20000 [06:50<00:00, 48.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples loaded: 20000\n",
      "Input graphs shape: (20000, 2, 150, 150)\n",
      "Input features shape: (20000, 2, 150, 200)\n",
      "Input speedups (target) shape: (20000, 1)\n",
      "Data saved to ./data/cdfg_control-call_20000samples_150x150.npz\n",
      "Samples information saved to ./data/selected_cdfg_control-call_20000samples_150x150.yaml\n"
     ]
    }
   ],
   "source": [
    "representation = ('control', 'call')\n",
    "\n",
    "output_data_file = f\"./data/cdfg_{'-'.join(representation)}_{no_samples}samples_{network_input_graph_shape[0]}x{network_input_graph_shape[1]}\"\n",
    "input_graphs, input_features, speedups = generate_sample(samples, representation)\n",
    "np.savez_compressed(output_data_file, graphs=input_graphs, features=input_features, speedups=speedups)\n",
    "print(f\"Data saved to {output_data_file}.npz\")\n",
    "\n",
    "output_samples_file = f\"./data/selected_cdfg_{'-'.join(representation)}_{no_samples}samples_{network_input_graph_shape[0]}x{network_input_graph_shape[1]}.yaml\"\n",
    "with open(output_samples_file, 'wt') as f:\n",
    "    yaml.dump(samples, f)\n",
    "print(f\"Samples information saved to {output_samples_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "atmospheric-retreat",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Samples generated: 100%|██████████| 20000/20000 [06:50<00:00, 48.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples loaded: 20000\n",
      "Input graphs shape: (20000, 2, 150, 150)\n",
      "Input features shape: (20000, 2, 150, 200)\n",
      "Input speedups (target) shape: (20000, 1)\n",
      "Data saved to ./data/cdfg_data-call_20000samples_150x150.npz\n",
      "Samples information saved to ./data/selected_cdfg_data-call_20000samples_150x150.yaml\n"
     ]
    }
   ],
   "source": [
    "representation = ('data', 'call')\n",
    "\n",
    "output_data_file = f\"./data/cdfg_{'-'.join(representation)}_{no_samples}samples_{network_input_graph_shape[0]}x{network_input_graph_shape[1]}\"\n",
    "input_graphs, input_features, speedups = generate_sample(samples, representation)\n",
    "np.savez_compressed(output_data_file, graphs=input_graphs, features=input_features, speedups=speedups)\n",
    "print(f\"Data saved to {output_data_file}.npz\")\n",
    "\n",
    "output_samples_file = f\"./data/selected_cdfg_{'-'.join(representation)}_{no_samples}samples_{network_input_graph_shape[0]}x{network_input_graph_shape[1]}.yaml\"\n",
    "with open(output_samples_file, 'wt') as f:\n",
    "    yaml.dump(samples, f)\n",
    "print(f\"Samples information saved to {output_samples_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "average-president",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Samples generated: 100%|██████████| 20000/20000 [06:50<00:00, 48.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples loaded: 20000\n",
      "Input graphs shape: (20000, 2, 150, 150)\n",
      "Input features shape: (20000, 2, 150, 200)\n",
      "Input speedups (target) shape: (20000, 1)\n",
      "Data saved to ./data/cdfg_control_20000samples_150x150.npz\n",
      "Samples information saved to ./data/selected_cdfg_control_20000samples_150x150.yaml\n"
     ]
    }
   ],
   "source": [
    "representation = ('control',)\n",
    "\n",
    "output_data_file = f\"./data/cdfg_{'-'.join(representation)}_{no_samples}samples_{network_input_graph_shape[0]}x{network_input_graph_shape[1]}\"\n",
    "input_graphs, input_features, speedups = generate_sample(samples, representation)\n",
    "np.savez_compressed(output_data_file, graphs=input_graphs, features=input_features, speedups=speedups)\n",
    "print(f\"Data saved to {output_data_file}.npz\")\n",
    "\n",
    "output_samples_file = f\"./data/selected_cdfg_{'-'.join(representation)}_{no_samples}samples_{network_input_graph_shape[0]}x{network_input_graph_shape[1]}.yaml\"\n",
    "with open(output_samples_file, 'wt') as f:\n",
    "    yaml.dump(samples, f)\n",
    "print(f\"Samples information saved to {output_samples_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "vocational-village",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Samples generated: 100%|██████████| 20000/20000 [06:51<00:00, 48.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples loaded: 20000\n",
      "Input graphs shape: (20000, 2, 150, 150)\n",
      "Input features shape: (20000, 2, 150, 200)\n",
      "Input speedups (target) shape: (20000, 1)\n",
      "Data saved to ./data/cdfg_data_20000samples_150x150.npz\n",
      "Samples information saved to ./data/selected_cdfg_data_20000samples_150x150.yaml\n"
     ]
    }
   ],
   "source": [
    "representation = ('data',)\n",
    "\n",
    "output_data_file = f\"./data/cdfg_{'-'.join(representation)}_{no_samples}samples_{network_input_graph_shape[0]}x{network_input_graph_shape[1]}\"\n",
    "input_graphs, input_features, speedups = generate_sample(samples, representation)\n",
    "np.savez_compressed(output_data_file, graphs=input_graphs, features=input_features, speedups=speedups)\n",
    "print(f\"Data saved to {output_data_file}.npz\")\n",
    "\n",
    "output_samples_file = f\"./data/selected_cdfg_{'-'.join(representation)}_{no_samples}samples_{network_input_graph_shape[0]}x{network_input_graph_shape[1]}.yaml\"\n",
    "with open(output_samples_file, 'wt') as f:\n",
    "    yaml.dump(samples, f)\n",
    "print(f\"Samples information saved to {output_samples_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "unknown-baking",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Samples generated: 100%|██████████| 20000/20000 [06:50<00:00, 48.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples loaded: 20000\n",
      "Input graphs shape: (20000, 2, 150, 150)\n",
      "Input features shape: (20000, 2, 150, 200)\n",
      "Input speedups (target) shape: (20000, 1)\n",
      "Data saved to ./data/cdfg_call_20000samples_150x150.npz\n",
      "Samples information saved to ./data/selected_cdfg_call_20000samples_150x150.yaml\n"
     ]
    }
   ],
   "source": [
    "representation = ('call',)\n",
    "\n",
    "output_data_file = f\"./data/cdfg_{'-'.join(representation)}_{no_samples}samples_{network_input_graph_shape[0]}x{network_input_graph_shape[1]}\"\n",
    "input_graphs, input_features, speedups = generate_sample(samples, representation)\n",
    "np.savez_compressed(output_data_file, graphs=input_graphs, features=input_features, speedups=speedups)\n",
    "print(f\"Data saved to {output_data_file}.npz\")\n",
    "\n",
    "output_samples_file = f\"./data/selected_cdfg_{'-'.join(representation)}_{no_samples}samples_{network_input_graph_shape[0]}x{network_input_graph_shape[1]}.yaml\"\n",
    "with open(output_samples_file, 'wt') as f:\n",
    "    yaml.dump(samples, f)\n",
    "print(f\"Samples information saved to {output_samples_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-million",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
