{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "absolute-photograph",
   "metadata": {},
   "source": [
    "# Generate CDFG Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "silent-grove",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import glob\n",
    "import numpy as np\n",
    "import random\n",
    "import tqdm\n",
    "\n",
    "from typing import Tuple, List, Dict\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from utils import yaml_load, yaml_write, get_section\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unexpected-compatibility",
   "metadata": {},
   "source": [
    "## Utilitary Functions\n",
    "\n",
    "These utilitary functions are used to select CDFGs and generate adjacency and features matrices to be used by GNNs.\n",
    "\n",
    "These functions use the database file to several cases, such as: check the number of nodes in the CDFGs, name of the files from a certian application and otimization sequence, *etc*.. \n",
    "\n",
    "The database file is a dictionary that contains information about applications and their optimization sequences, like this:\n",
    "\n",
    "```python\n",
    "{\n",
    "    # Information about application 1\n",
    "    application_1: {\n",
    "        # Application 1 optimized with sequence 0\n",
    "        0: {\n",
    "            cfg_file: '/path/to/cfg/file'\n",
    "            number_cfg_nodes: 10\n",
    "            cdfg_file: '/path/to/cdfg/file'\n",
    "            number_cdfg_nodes: 20\n",
    "            exectime: 1.234\n",
    "        }\n",
    "        # Application 1 optimized with sequence 1\n",
    "        1: {   \n",
    "            cfg_file: '/path/to/cfg/file'\n",
    "            number_cfg_nodes: 15\n",
    "            cdfg_file: '/path/to/cdfg/file'\n",
    "            number_cdfg_nodes: 22\n",
    "            exectime: 0.987\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Information about application 2\n",
    "    application_2: {\n",
    "        # Application 2 optimized with sequence 0\n",
    "        0: {\n",
    "            ...\n",
    "        }\n",
    "        ...\n",
    "    }\n",
    "    ...\n",
    " }\n",
    "```\n",
    "\n",
    "See `building_metadata` notebook for more information about database file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "thorough-conviction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_cdfg_files_below_order(metadata: dict, order: int) -> dict:\n",
    "    \"\"\"Filter CDFG files from metadata database which adjacency matrix is below some order (number of nodes).\n",
    "    \n",
    "    Parameters:\n",
    "        metadata (dict): Dictionary of metadata datasabe. See `building_metadata` notebook for explanation about metadata\n",
    "        order (int): Order of adjacency matrix to filter\n",
    "    \n",
    "    Returns:\n",
    "        The filtered metadata database dictionary  \n",
    "    \"\"\"\n",
    "    # Lets filter CDFG files in which number of nodes is less than an order\n",
    "    filtered_graph_files = {\n",
    "        benchmark_name: {\n",
    "            opt_seq: opt_values \n",
    "            for opt_seq, opt_values in values.items() if opt_values['number_cdfg_nodes'] < order\n",
    "        } for benchmark_name, values in metadata.items()\n",
    "    }\n",
    "\n",
    "    # Remove applications that has less than 2 graphs\n",
    "    filtered_graph_files = {benchmark_name: values for benchmark_name, values in filtered_graph_files.items() if len(values) > 2}\n",
    "    print(f\"Number of graphs with adjacency matrix below order {order}: {sum([len(values) for _, values in filtered_graph_files.items()])}\")\n",
    "    # Return filtered metadata\n",
    "    return filtered_graph_files\n",
    "\n",
    "def sample_cdfg_files(metadata: dict, num_samples: int, sample_condition: callable = None, weighted: bool = True, tries: int = 10) -> List[Tuple[str, str, float]]:\n",
    "    \"\"\"Sample CDFGs from metadata dict which satisfy a sample condition. Each sample contains 2 CDFG files of the same application with different optimization sequences. \n",
    "\n",
    "    Parameters:\n",
    "        metadata (dict): Dictionary of metadata datasabe.\n",
    "        num_samples (int): Number of samples to pick\n",
    "        sample_condition (callable): A function determining if the two CDFG files satisfy a condition. The function must receive 2 parameters and return a\n",
    "                                boolean indicating if the sample is valid (True) or not (False). The parameters are 2 dictionaries with information about the \n",
    "                                CDFGs. Each dictionary contains the following information:\n",
    "                                * cfg_file (str): /path/to/cfg/file\n",
    "                                * cdfg_file (str): /path/to/cdfg/file\n",
    "                                * number_cdfg_nodes (int): Number of nodes in CDFG representation\n",
    "                                * number_cfg_nodes (int): Number of nodes in CFG representation\n",
    "                                * exectime: Execution time of the application\n",
    "        weighted (bool): True if selection of samples must by weighted by application and False otherwise\n",
    "        \n",
    "    Returns:\n",
    "        A list of tuples, with `num_samples` elements, where each tuple has the following elements:\n",
    "        * Path to first CDFG file\n",
    "        * Path to second CDFG file\n",
    "        * Relative speedup. Execution time of application from first CDFG over execution time of application from second CDFG\n",
    "        Returns None if the informed number of samples is not reached\n",
    "    \"\"\"\n",
    "    samples = []\n",
    "    apps = list(metadata.keys())\n",
    "    \n",
    "    if weighted:\n",
    "        # Weighted selection based on how many sequeces is in each app\n",
    "        total_app_seq = sum([len(opt_sequences) for _, opt_sequences in metadata.items()])\n",
    "        weights = [len(opt_sequences)/total_app_seq for _, opt_sequences in metadata.items()]\n",
    "    else:\n",
    "        # Equal weights for all elements\n",
    "        weights = [1/len(apps)] * len(apps)\n",
    "    \n",
    "    # Returns None if no sample that satisfy condition match\n",
    "    def try_sample(tries: int = 10):\n",
    "        \"\"\"Inner function used to pick a sample (i.e., two graph files app:opt1, app:opt2) that satisfy a sample condition\n",
    "\n",
    "        Params:\n",
    "            tries (int): NUmber of tries to pick a sample that satisfy condition.\n",
    "\n",
    "        Returns:\n",
    "            A 3-element tuple with:\n",
    "            * The name of the application\n",
    "            * The 1st optimization sequence for that application\n",
    "            * The 2nd optimization sequence for that application\n",
    "            Returns None if could not pick any sample that matches the sample condition \n",
    "        \"\"\"\n",
    "        # Tries to pick two CDFGs for same application for 'tries' times\n",
    "        for i in range(0, tries):\n",
    "            # Choose an application\n",
    "            app = np.random.choice(apps, p=weights)\n",
    "            # Choose 2 optimization sequences for that application\n",
    "            opt_seq1, opt_seq2 = random.sample(list(metadata[app].keys()), 2)\n",
    "            # Does it have a sampling condition?\n",
    "            if sample_condition is not None:\n",
    "                # Applies the condition\n",
    "                if sample_condition(metadata[app][opt_seq1], metadata[app][opt_seq2]) == True:\n",
    "                    return (app, opt_seq1, opt_seq2)\n",
    "            # If no sampling condition is given, just return the picked value \n",
    "            else:\n",
    "                return (app, opt_seq1, opt_seq2)\n",
    "        # Return None if no sample was retrieved\n",
    "        return None\n",
    "        \n",
    "    # Pick 'num_samples' samples\n",
    "    for i in range(0, num_samples):\n",
    "        # Try to pick a sample for 'tries' times\n",
    "        sample = try_sample(tries=tries)\n",
    "        # Raises exception if no samples could be picked\n",
    "        if not sample:\n",
    "            raise Exception(\"Could not generate number of samples with the valid sample condition\")\n",
    "        \n",
    "        # Generate a tuple (CDFG1, CDFG2, RelativeSpeedup) and append to samples list\n",
    "        app, opt_seq1, opt_seq2 = sample\n",
    "        t = (\n",
    "            metadata[app][opt_seq1]['cdfg_file'], \n",
    "            metadata[app][opt_seq2]['cdfg_file'],\n",
    "            metadata[app][opt_seq1]['exectime']/metadata[app][opt_seq2]['exectime']            \n",
    "        )\n",
    "        samples.append(t)\n",
    "\n",
    "    # Return samples\n",
    "    return samples\n",
    "\n",
    "no_total_features = 0\n",
    "no_total_invalid_features = 0\n",
    "\n",
    "def generate_graph_feature_matrices(network_shape: Tuple[int, int], features_shape: Tuple[int, int], edges: dict, edge_features: dict, node_features: dict, representation: tuple, embeddings_dict: dict) -> Tuple[np.array, np.array]:\n",
    "    \"\"\"Generate the graph's adjacency matrix and the feature matrix from sparse data (dict).\n",
    "    \n",
    "    Parameters:\n",
    "        network_shape (tuple):  Shape of the graph's adjacency matrix used as input to GNN. \n",
    "                                The matrix is filled with zeros if the graph has less nodes than network_shape\n",
    "        features_shape (tuple): Shape of the feature matrix used as input to GNN\n",
    "                                The matrix is filled with zeros if the graph has less nodes than features_shape\n",
    "        edges (dict): Dictionary with the edges. Each key is the edge id and each value is a 2-element tuple with origin and destiny of the edge\n",
    "        edge_features (dict): Dictionary with the type of each edge. Each key is the edge id and each value is a 1-element tuple with the edge's type. Type is 0, 1 or 2, for control, data and call edges\n",
    "        node_features (dict): Dictionary describing the feature vector of each node. Each dictionary's key is the node_id and each value is the ID of an inst2vec feature vector. \n",
    "        representation (tuple): Lists which representations must be included in the graph. Must be any combination of these values: 'control', 'data' or 'call'.\n",
    "        embeddings_dict (dict): Embbeding inst2vec dictionary. Each key is the inst2vec feature vector's ID and the each value is a 200-element list describing the feature vector\n",
    "        \n",
    "    Returns:\n",
    "        A 2-element tuple:\n",
    "        * The graph matrix\n",
    "        * The feature matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    global no_total_features, no_total_invalid_features\n",
    "    # Which edges to include in the graph\n",
    "    valid_edges = {\n",
    "        0: 'control' in representation,\n",
    "        1: 'data' in representation,\n",
    "        2: 'call' in representation\n",
    "    }\n",
    "    \n",
    "    adj_matrix = np.full((network_shape), False, dtype='bool')\n",
    "    feature_matrix = np.zeros((features_shape), dtype='float32')\n",
    "    \n",
    "    # Fill the graph's adjacency matrix with edges\n",
    "    for edge_no, edge in edges.items():\n",
    "        edge_type = edge_features[edge_no][0]\n",
    "        if valid_edges[edge_type] == True:\n",
    "            adj_matrix[edge[0]][edge[1]] = True\n",
    "    \n",
    "    # non_zero_nodes = {node_no: is_not_zero_row for node_no, is_not_zero_row in enumerate(adj_matrix.any(axis=1))}\n",
    "    \n",
    "    # Add inst2vec features to nodes\n",
    "    for node_no, feature_no in node_features.items():\n",
    "        # if non_zero_nodes[node_no] == True:\n",
    "        feature_no = feature_no[0]\n",
    "        feature_matrix[node_no] = embeddings_dict[feature_no]\n",
    "        if feature_no == 8564:\n",
    "            no_total_invalid_features += 1\n",
    "        no_total_features += 1\n",
    "    \n",
    "    return adj_matrix, feature_matrix  \n",
    "\n",
    "def load_sample_files(sample_tuple: Tuple[str, str, float], network_shape: Tuple[int, int], features_shape: Tuple[int, int], representation: tuple, embeddings_dict: dict) -> Tuple[np.array, np.array, np.array]:\n",
    "    \"\"\"Given a tuple with CDFG filenames, load each CDFG and generate their adjacency and feature matrices.\n",
    "    \n",
    "    Parameters:\n",
    "        sample_tuple (tuple): A 3-element tuple, with:\n",
    "                * Path to first CDFG file\n",
    "                * Path to second CDFG file\n",
    "                * Relative speedup. Execution time of application from first CDFG over execution time of application from second CDFG\n",
    "        network_shape (tuple):  Shape of the graph's adjacency matrix used as input to GNN. \n",
    "        features_shape (tuple): Shape of the feature matrix used as input to GNN\n",
    "        representation (tuple): Lists which representations must be included in the graph. Must be any combination of these values: 'control', 'data' or 'call'.\n",
    "        embeddings_dict (dict): Embbeding inst2vec dictionary. Each key is the inst2vec feature vector's ID and the each value is a 200-element list describing the feature vector\n",
    "\n",
    "    Returns:\n",
    "        A 3-element tuple with:\n",
    "        * A matrix with 2 CDFGs\n",
    "        * A matrix with 2 CDFGs features\n",
    "        * The speedup (1-element matrix)\n",
    "    \"\"\"\n",
    "    \n",
    "    def load_graph_from_file(filename: str) -> Tuple[dict, dict]:\n",
    "        \"\"\"Inner function used to load the graph from a file\n",
    "        \n",
    "        Parameters:\n",
    "            filename (str): Name of the file with CDFG\n",
    "        \n",
    "        Returns:\n",
    "            A 2-element tuple with the graph, represented as adjacency list and the features\n",
    "        \"\"\"\n",
    "        x = yaml_load(filename)\n",
    "        return x['edges'], x['edges_features'], x['nodes_features']\n",
    "    \n",
    "    # Load graph from first file and generate the graph and feature matrices\n",
    "    edges_1, edge_feat_1, feat_1 = load_graph_from_file(sample_tuple[0])\n",
    "    graph1, features1 = generate_graph_feature_matrices(\n",
    "        network_shape, features_shape, edges_1, edge_feat_1, \n",
    "        feat_1, representation, embeddings_dict)\n",
    "    # Load graph from second file and generate the graph and feature matrices\n",
    "    edges_2, edge_feat_2, feat_2 = load_graph_from_file(sample_tuple[1])\n",
    "    graph2, features2 = generate_graph_feature_matrices(\n",
    "        network_shape, features_shape, edges_2, edge_feat_2, \n",
    "        feat_2, representation, embeddings_dict\n",
    "    )\n",
    " \n",
    "    # Generate a matrix with the 2 graph matrices\n",
    "    graphs = np.array([graph1, graph2], dtype='bool')\n",
    "    # Generate a matrix with the 2 feature matrices\n",
    "    features = np.array([features1, features2], dtype='float32') \n",
    "    # Generate 1-element speedup array\n",
    "    speedup_array = np.array([sample_tuple[2]], dtype='float32')\n",
    "    \n",
    "    return graphs, features, speedup_array\n",
    "\n",
    "\n",
    "def generate_samples(samples: List[Tuple[str, str, float]], network_shape: Tuple[int, int], feature_shape: Tuple[int, int], representation: tuple, embeddings_dict: dict, desc: str = 'Samples generated'):\n",
    "    \"\"\"Generate samples used as input to a GNN\n",
    "    \n",
    "    Parameters:\n",
    "        samples (list): List of tuple, where each tuple has the following elements:\n",
    "                * Path to first CDFG file\n",
    "                * Path to second CDFG file\n",
    "                * Relative speedup. Execution time of application from first CDFG over execution time of application from second CDFG\n",
    "        network_shape (tuple):  Shape of the graph's adjacency matrix used as input to GNN. \n",
    "        features_shape (tuple): Shape of the feature matrix used as input to GNN\n",
    "        representation (tuple): Lists which representations must be included in the graph. Must be any combination of these values: 'control', 'data' or 'call'.\n",
    "        embeddings_dict (dict): Embbeding inst2vec dictionary. Each key is the inst2vec feature vector's ID and the each value is a 200-element list describing the feature vector\n",
    "        desc (str): Optional description for TQDM bar\n",
    "        \n",
    "    Returns:\n",
    "        A 3-element tuple with:\n",
    "        * A matrix with all samples, each sample has 2 CDFGs\n",
    "        * A matrix with all samples, each sample has 2 CDFGs features\n",
    "        * A matrix with all samples, each sample has the speedup\n",
    "    \"\"\"    \n",
    "    global no_total_features, no_total_invalid_features\n",
    "\n",
    "    for rep in representation:\n",
    "        assert rep in ['control', 'data', 'call'], f\"Invalid representation {rep}\"\n",
    "    \n",
    "    sampled_graphs = np.zeros((len(samples), 2, network_shape[0], network_shape[1]), dtype='bool')\n",
    "    sampled_features = np.zeros((len(samples), 2, feature_shape[0], feature_shape[1]), dtype='float32')\n",
    "    sampled_speedups = np.zeros((len(samples), 1), dtype='float32')\n",
    "\n",
    "    # Some counters\n",
    "    equal_graphs = 0\n",
    "    equal_graphs_features = 0\n",
    "    no_total_features = 0\n",
    "    no_total_invalid_features = 0\n",
    "    \n",
    "    # Load each sample and store in input_graphs, input_features and speedups\n",
    "    for i in tqdm.tqdm(range(0, len(samples)), desc=desc):\n",
    "        # This function return a list of tuples, where each tuple is composed by:\n",
    "        # np.array with 2 graphs, np.array with 2 features, speedup\n",
    "        graphs, features, speedup = load_sample_files(samples[i], network_shape, feature_shape, representation, embeddings_dict)           \n",
    "        sampled_graphs[i] = graphs\n",
    "        sampled_features[i] = features\n",
    "        sampled_speedups[i] = speedup\n",
    " \n",
    "        if np.array_equal(graphs[0], graphs[1]):\n",
    "            equal_graphs += 1\n",
    "            if np.array_equal(features[0], features[1]):\n",
    "                equal_graphs_features += 1\n",
    "\n",
    "    print(f\"Number of samples loaded: {len(samples)}\")\n",
    "    print(f\"Graphs shape: {sampled_graphs.shape}\")\n",
    "    print(f\"Features shape: {sampled_features.shape}\")\n",
    "    print(f\"Speedups (target) shape: {sampled_speedups.shape}\")\n",
    "    print(f\"Number of samples with equal graphs: {equal_graphs}\")\n",
    "    print(f\"Number of samples with equal graphs and equal features: {equal_graphs_features}\")\n",
    "        \n",
    "    print(f\"Number of features assigned (FA): {no_total_features}\")\n",
    "    print(f\"Invalid number of representations assigned: {no_total_invalid_features} (in relation to FA: {no_total_invalid_features/no_total_features}%)\")\n",
    "    \n",
    "    return sampled_graphs, sampled_features, sampled_speedups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "empirical-graduation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_filenames(data_dir: str, num_samples: int, network_shape: Tuple[int, int], tag) -> Tuple[str, str]:\n",
    "    \"\"\"Generate the file paths to store the samples\n",
    "    \n",
    "    Parameters:\n",
    "        data_dir (str): Root data directory to store information\n",
    "        num_samples (int): Number of samples generated\n",
    "        network_shape (tuple):  Shape of the graph's adjacency matrix used as input to GNN\n",
    "        \n",
    "    Returns:\n",
    "        A 2-element tuple with:\n",
    "        * The name of the file to store the samples\n",
    "        * The name of the file to store samples information (which CDFG files were selected)\n",
    "    \"\"\"\n",
    "    output_data_file = f\"cdfgs_{tag}_{num_samples}samples_{network_shape[0]}x{network_shape[1]}\"\n",
    "    output_data_file = os.path.join(data_dir, output_data_file)\n",
    "    \n",
    "    selected_data_file = f\"selected_cdfgs_{tag}_{num_samples}samples_{network_shape[0]}x{network_shape[1]}.yaml\"\n",
    "    selected_data_file = os.path.join(data_dir, selected_data_file)\n",
    "    return output_data_file, selected_data_file\n",
    "\n",
    "def save_data_file(output_data_file: str, output_samples_file: str, samples: List[Tuple[str, str, float]], graphs: np.array, features: np.array, speedups: np.array):\n",
    "    \"\"\"Save samples to a .npz file\n",
    "    \n",
    "    Parameters:\n",
    "        output_data_file (str): Path to store the samples to npz file (graphs, feaures and speedups)\n",
    "        output_samples_file (str): Path to store information about samples (which files correspond to each sample)\n",
    "        samples (list): Files used to generate the samples\n",
    "        graphs (np.array): Matrix with all graphs\n",
    "        features (np.array): Matrix with all features\n",
    "        speedups (np.array): Matrix with all speedups\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    np.savez_compressed(output_data_file, graphs=graphs, features=features, speedups=speedups)\n",
    "    print(f\"Data saved to {output_data_file}.npz\")\n",
    "    \n",
    "    yaml_write(output_samples_file, samples)\n",
    "    print(f\"Samples information saved to {output_samples_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-texture",
   "metadata": {},
   "source": [
    "## Common variables for all shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "boxed-bikini",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata loaded from './data/ccpe-applications-information.yaml'\n",
      "Embbedings loaded from ./data/inst2vec/emb.p\n"
     ]
    }
   ],
   "source": [
    "# Default root directory to store all informations \n",
    "data_dir = './data'\n",
    "# Metadata database file\n",
    "metadata_file = './data/ccpe-applications-information.yaml'\n",
    "# Load metadata database\n",
    "metadata_info = yaml_load(metadata_file)\n",
    "print(f\"Metadata loaded from '{metadata_file}'\")\n",
    "\n",
    "# Embeddings file\n",
    "embeddings_file = './data/inst2vec/emb.p'\n",
    "# Embeddings dict\n",
    "embeddings_info = np.load(embeddings_file, allow_pickle=True)\n",
    "print(f'Embbedings loaded from {embeddings_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moving-gathering",
   "metadata": {},
   "source": [
    "## Generating representations for (150x150) shape\n",
    "\n",
    "CDFG representations with the following edges:\n",
    "- Control, data and call edges\n",
    "- Control and data edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-aluminum",
   "metadata": {},
   "source": [
    "The samples generation is composed by 4 steps:\n",
    "1. Remove CDFG files where the number of CDFG nodes is higher than a order (speficied by network_graph_shape variable). \n",
    "2. Sample CDFG files. This will generate a list of tuples, where each tuple is composed by: path to CDFG1, path to CDFG2, speedup between CDFG1/CDFG2. The two CDFGs are from the same application, but with different optimization sequences.\n",
    "3. Generate representations from sampled CDFG files (adjacency matrices, feature matrices and speedup matrices)\n",
    "4. Store samples to .npz file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "functioning-vegetable",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of graphs with adjacency matrix below order 150: 887\n",
      "Class A samples...\n",
      "Class B samples...\n",
      "Class C samples...\n",
      "Class D samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Samples for representation ('control', 'data', 'call'):   0%|          | 10/20000 [00:00<03:30, 94.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating representation for: ('control', 'data', 'call')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Samples for representation ('control', 'data', 'call'): 100%|██████████| 20000/20000 [05:05<00:00, 65.41it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples loaded: 20000\n",
      "Graphs shape: (20000, 2, 150, 150)\n",
      "Features shape: (20000, 2, 150, 200)\n",
      "Speedups (target) shape: (20000, 1)\n",
      "Number of samples with equal graphs: 0\n",
      "Number of samples with equal graphs and equal features: 0\n",
      "Number of features assigned (FA): 3596299\n",
      "Invalid number of representations assigned: 2328832 (in relation to FA: 0.6475635090408223%)\n",
      "Data saved to ./data/cdfgs_control-data-call_20000samples_150x150.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Samples for representation ('control', 'data'):   0%|          | 12/20000 [00:00<02:47, 119.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples information saved to ./data/selected_cdfgs_control-data-call_20000samples_150x150.yaml\n",
      "Finished generation for representation ('control', 'data', 'call')\n",
      "\n",
      "Generating representation for: ('control', 'data')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Samples for representation ('control', 'data'): 100%|██████████| 20000/20000 [04:59<00:00, 66.82it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples loaded: 20000\n",
      "Graphs shape: (20000, 2, 150, 150)\n",
      "Features shape: (20000, 2, 150, 200)\n",
      "Speedups (target) shape: (20000, 1)\n",
      "Number of samples with equal graphs: 0\n",
      "Number of samples with equal graphs and equal features: 0\n",
      "Number of features assigned (FA): 3596299\n",
      "Invalid number of representations assigned: 2328832 (in relation to FA: 0.6475635090408223%)\n",
      "Data saved to ./data/cdfgs_control-data_20000samples_150x150.npz\n",
      "Samples information saved to ./data/selected_cdfgs_control-data_20000samples_150x150.yaml\n",
      "Finished generation for representation ('control', 'data')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Defining some variables\n",
    "network_graph_shape = (150, 150)     # Network input graph's shape\n",
    "network_features_shape = (150, 200)  # Network input feature's shape\n",
    "n_samples = 20000                    # Number of samples to generate. Each sample is composed by 2 graphs\n",
    "representations_to_generate = [\n",
    "    ('control', 'data', 'call'),\n",
    "    ('control', 'data'),\n",
    "    #('control', 'call'),\n",
    "    #('data', 'call'),\n",
    "    #('control',),\n",
    "    #('data',),\n",
    "    #('call',)\n",
    "]\n",
    "\n",
    "# 1. Filtering CFGs that number of nodes is below 'network_graph_shape'\n",
    "cfg_files = filter_cdfg_files_below_order(metadata_info, network_graph_shape[0])\n",
    "\n",
    "# Conditions to compose each class of samples (A, B, C and D)\n",
    "classA_cond = lambda opt1, opt2: opt1['exectime']/opt2['exectime'] < 0.45\n",
    "classB_cond = lambda opt1, opt2: opt1['exectime']/opt2['exectime'] <= 0.80 and opt1['exectime']/opt2['exectime'] >= 0.45\n",
    "classC_cond = lambda opt1, opt2: opt1['exectime']/opt2['exectime'] <= 1.33 and opt1['exectime']/opt2['exectime'] > 0.80\n",
    "classD_cond = lambda opt1, opt2: opt1['exectime']/opt2['exectime'] > 1.33\n",
    "\n",
    "# 2. Sample CFG files based on conditions. 1/4 of CFG files for each condition. \n",
    "print(\"Class A samples...\")\n",
    "sample_files =  sample_cdfg_files(cfg_files, n_samples//4, sample_condition=classA_cond, tries=1000)\n",
    "print(\"Class B samples...\")\n",
    "sample_files += sample_cdfg_files(cfg_files, n_samples//4, sample_condition=classB_cond, tries=1000)\n",
    "print(\"Class C samples...\")\n",
    "sample_files += sample_cdfg_files(cfg_files, n_samples//4, sample_condition=classC_cond, tries=1000)\n",
    "print(\"Class D samples...\")\n",
    "sample_files += sample_cdfg_files(cfg_files, n_samples//4, sample_condition=classD_cond, tries=1000)\n",
    "    \n",
    "for representation in representations_to_generate:\n",
    "    print(f'Generating representation for: {representation}')\n",
    "    \n",
    "    output_data_file, output_samples_file = get_output_filenames(data_dir, n_samples, network_graph_shape, '-'.join(representation))  # Paths to store samples\n",
    "    \n",
    "    # 3. Generate samples from files\n",
    "    graphs, features, speedups = generate_samples(sample_files, network_graph_shape, network_features_shape, representation, embeddings_info, desc=f'Samples for representation {representation}')\n",
    "\n",
    "    # 4. Save all samples to a .npz file\n",
    "    save_data_file(output_data_file, output_samples_file, sample_files, graphs, features, speedups)\n",
    "    \n",
    "    print(f\"Finished generation for representation {representation}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
