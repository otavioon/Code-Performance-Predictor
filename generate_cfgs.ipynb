{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate CFG Input Representations (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import glob\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from spektral.datasets import delaunay\n",
    "from spektral.layers import *\n",
    "from spektral.utils.convolution import localpooling_filter\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tqdm.contrib.concurrent import process_map, thread_map\n",
    "\n",
    "from utils import yaml_load, get_section\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_cfgs_files_below_shape(metadata_dict, max_shape):\n",
    "    # Lets filter CFG files whose number of nodes is less than max_shape\n",
    "    filtered_graph_files = {\n",
    "        benchmark_name: {\n",
    "            opt_seq: opt_values \n",
    "            for opt_seq, opt_values in values.items() if opt_values['number_cfg_nodes'] < max_shape[0]\n",
    "        } for benchmark_name, values in metadata_dict.items()\n",
    "    }\n",
    "\n",
    "    # Remove applications that has less than 2 graphs with less than network_input_graph_shape\n",
    "    filtered_graph_files = {benchmark_name: values for benchmark_name, values in filtered_graph_files.items() if len(values) > 2}\n",
    "    print(f\"Number of graphs with adjacency matrix below shape {max_shape}: {sum([len(values) for _, values in filtered_graph_files.items()])}\")\n",
    "    return filtered_graph_files\n",
    "\n",
    "def sample_cfgs(metadata_dict, num_samples):\n",
    "    samples = []\n",
    "    for s in random.choices(list(metadata_dict.keys()), k=num_samples):\n",
    "        opt_seq1, opt_seq2 = random.sample(list(metadata_dict[s].keys()), 2)\n",
    "        t = (\n",
    "            metadata_dict[s][opt_seq1]['cfg_file'], \n",
    "            metadata_dict[s][opt_seq2]['cfg_file'],\n",
    "            metadata_dict[s][opt_seq1]['exectime']/metadata_dict[s][opt_seq2]['exectime']\n",
    "        )\n",
    "        samples.append(t)\n",
    "\n",
    "    print(f\"Sampled {len(samples)} CFGs\")\n",
    "    print(f\"First sample of {len(samples)} samples (example of output): {samples[0]}\")\n",
    "    return samples\n",
    "\n",
    "def load_graph_from_file(filename: str) -> tuple:\n",
    "    x = yaml_load(filename)\n",
    "    return x['nodes'], x['nodes_features']\n",
    "\n",
    "def generate_graph_matrix(network_shape, features_shape, nodes, nodes_features) -> tuple:\n",
    "    # The graph is represented as a list of adjacency. Let's transform it to an adjacency matrix\n",
    "    graph = np.full(network_shape, False, dtype='bool')\n",
    "    for node, node_list in nodes.items():\n",
    "        for n in node_list:\n",
    "            graph[node][n] = True\n",
    "\n",
    "    # Lets read the features from the graphs\n",
    "    features = np.zeros(features_shape, dtype='float32')\n",
    "    for node, node_list in nodes_features.items():\n",
    "        features[node] = node_list\n",
    "\n",
    "    return graph, features\n",
    "\n",
    "def load_sample_file(sample_tuple: tuple, network_shape: tuple, features_shape: tuple) -> tuple:\n",
    "    graph1, features1 = load_graph_from_file(sample_tuple[0])\n",
    "    graph1, features1 = generate_graph_matrix(network_shape, features_shape, graph1, features1)\n",
    "    graph2, features2 = load_graph_from_file(sample_tuple[1])\n",
    "    graph2, features2 = generate_graph_matrix(network_shape, features_shape, graph2, features2)\n",
    " \n",
    "    graphs = np.zeros((2, network_shape[0], network_shape[1]), dtype='bool')\n",
    "    graphs[0] = graph1\n",
    "    graphs[1] = graph2\n",
    "\n",
    "    features = np.zeros((2, features_shape[0], features_shape[1]), dtype='float32')\n",
    "    features[0] = features1\n",
    "    features[1] = features2\n",
    "    \n",
    "    speedup_array = np.array([sample_tuple[2]], dtype='float32')\n",
    "    \n",
    "    return graphs, features, speedup_array\n",
    "\n",
    "def generate_samples(samples: list, network_shape: tuple, feature_shape: tuple, desc: str = 'Samples generated'):\n",
    "    input_graphs = np.empty((len(samples), 2, network_shape[0], network_shape[1]), dtype='bool')\n",
    "    input_features = np.empty((len(samples), 2, feature_shape[0], feature_shape[1]), dtype='float32')\n",
    "    speedups = np.empty((len(samples), 1), dtype='float32')\n",
    "    \n",
    "    # Some counters\n",
    "    i = 0\n",
    "    equal_graphs = 0\n",
    "    \n",
    "    # Load each sample and store in input_graphs, input_features and speedups\n",
    "    for sample in tqdm.tqdm(samples, desc=desc):\n",
    "        # This function return a list of tuples, where each tuple is composed by:\n",
    "        # np.array with 2 graphs, np.array with 2 features, speedup\n",
    "        graphs, features, speedup = load_sample_file(sample, network_shape, feature_shape)           \n",
    "        input_graphs[i] = graphs\n",
    "        input_features[i] = features\n",
    "        speedups[i] = speedup\n",
    "        i += 1\n",
    "        if np.array_equal(graphs[0], graphs[1]):\n",
    "            equal_graphs += 1\n",
    "\n",
    "    print(f\"Number of samples loaded: {len(samples)}\")\n",
    "    print(f\"Graphs shape: {input_graphs.shape}\")\n",
    "    print(f\"Features shape: {input_features.shape}\")\n",
    "    print(f\"Speedups (target) shape: {speedups.shape}\")\n",
    "    print(f\"Number of sampes with equal graphs: {equal_graphs}\")\n",
    "    \n",
    "    #np.savez_compressed(output_file, graphs=input_graphs, features=input_features, speedups=speedups)\n",
    "    #print(f\"Representation {representation} saved to {output_file}\")\n",
    "    return input_graphs, input_features, speedups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common variables for all representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata loaded\n"
     ]
    }
   ],
   "source": [
    "data_dir = './data'\n",
    "metadata_file = './data/ccpe-applications-information.yaml'\n",
    "metadata_info = yaml_load(metadata_file)\n",
    "print('Metadata loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_filenames(data_dir: str, num_samples: int, network_shape: tuple) -> tuple:\n",
    "    output_data_file = f\"cfgs_{num_samples}samples_{network_shape[0]}x{network_shape[1]}\"\n",
    "    output_data_file = os.path.join(data_dir, output_data_file)\n",
    "    \n",
    "    selected_data_file = f\"selected_cfgs_{num_samples}samples_{network_shape[0]}x{network_shape[1]}.yaml\"\n",
    "    selected_data_file = os.path.join(data_dir, selected_data_file)\n",
    "    return output_data_file, selected_data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_file(output_data_file: str, output_samples_file: str, samples: list, graphs, features, speedups):\n",
    "    np.savez_compressed(output_data_file, graphs=graphs, features=features, speedups=speedups)\n",
    "    print(f\"Data saved to {output_data_file}.npz\")\n",
    "    \n",
    "    with open(output_samples_file, 'wt') as f:\n",
    "        yaml.dump(samples, f)\n",
    "    print(f\"Samples information saved to {output_samples_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate representations for (150x150) shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Samples generated:   0%|          | 1/20000 [00:00<36:03,  9.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of graphs with adjacency matrix below shape (150, 150): 17092\n",
      "Sampled 20000 CFGs\n",
      "First sample of 20000 samples (example of output): ('./data/ccpe-dados/cfg.llvm/extracted/PolyBench.linear-algebra-blas-syr2k.0.96.ll.cfg.yaml', './data/ccpe-dados/cfg.llvm/extracted/PolyBench.linear-algebra-blas-syr2k.0.40.ll.cfg.yaml', 1.1450459163531148)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Samples generated: 100%|██████████| 20000/20000 [19:17<00:00, 17.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples loaded: 20000\n",
      "Graphs shape: (20000, 2, 150, 150)\n",
      "Features shape: (20000, 2, 150, 67)\n",
      "Speedups (target) shape: (20000, 1)\n",
      "Number of sampes with equal graphs: 983\n",
      "Data saved to ./data/cfgs_20000samples_150x150.npz\n",
      "Samples information saved to ./data/selected_cfgs_20000samples_150x150.yaml\n"
     ]
    }
   ],
   "source": [
    "# Defining some useful variables\n",
    "network_graph_shape = (150, 150)\n",
    "network_features_shape = (150, 67)\n",
    "n_samples = 20000  # Number of samples to generate. Each sample is composed by 2 graphs\n",
    "\n",
    "cfg_files = filter_cfgs_files_below_shape(metadata_info, network_graph_shape)\n",
    "samples = sample_cfgs(cfg_files, n_samples)\n",
    "\n",
    "output_data_file, output_samples_file = get_output_filenames(data_dir, n_samples, network_graph_shape)\n",
    "graphs, features, speedups = generate_samples(samples, network_graph_shape, network_features_shape)\n",
    "save_data_file(output_data_file, output_samples_file, samples, graphs, features, speedups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate representations for (300x300) shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Samples generated:   0%|          | 0/20000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of graphs with adjacency matrix below shape (300, 300): 19837\n",
      "Sampled 20000 CFGs\n",
      "First sample of 20000 samples (example of output): ('./data/ccpe-dados/cfg.llvm/extracted/McGill.chomp.0.89.ll.cfg.yaml', './data/ccpe-dados/cfg.llvm/extracted/McGill.chomp.0.0.ll.cfg.yaml', 1.0102431352808965)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Samples generated: 100%|██████████| 20000/20000 [22:44<00:00, 14.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples loaded: 20000\n",
      "Graphs shape: (20000, 2, 300, 300)\n",
      "Features shape: (20000, 2, 300, 67)\n",
      "Speedups (target) shape: (20000, 1)\n",
      "Number of sampes with equal graphs: 861\n",
      "Data saved to ./data/cfgs_20000samples_300x300.npz\n",
      "Samples information saved to ./data/selected_cfgs_20000samples_300x300.yaml\n"
     ]
    }
   ],
   "source": [
    "# Defining some useful variables\n",
    "network_graph_shape = (300, 300)\n",
    "network_features_shape = (300, 67)\n",
    "n_samples = 20000  # Number of samples to generate. Each sample is composed by 2 graphs\n",
    "\n",
    "cfg_files = filter_cfgs_files_below_shape(metadata_info, network_graph_shape)\n",
    "samples = sample_cfgs(cfg_files, n_samples)\n",
    "\n",
    "output_data_file, output_samples_file = get_output_filenames(data_dir, n_samples, network_graph_shape)\n",
    "graphs, features, speedups = generate_samples(samples, network_graph_shape, network_features_shape)\n",
    "save_data_file(output_data_file, output_samples_file, samples, graphs, features, speedups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
